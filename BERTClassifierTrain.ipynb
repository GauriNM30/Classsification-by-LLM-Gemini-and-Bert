{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c026da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -q transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33db83b-ac2c-4292-b704-436af372c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76986960-6258-4977-9f08-12df689a0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb18dc4-5e3a-42bc-ac74-284233884c1f",
   "metadata": {},
   "source": [
    "# Build Training Set\n",
    "\n",
    "df_sampled contains training data which is retrieved using build_training_set method from Utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2435c39a-7037-4f48-b9a8-a1c3ec4692a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Produced by Keith G. RichardsonChrist, Christi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>The CRIMINOLOGY SERIES.1. The Female Offender....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Produced by Heiko Evermann, Sandra Eder and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>Produced by Chris Curnow, Paul Clark, and the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Produced by Juliet Sutherland, Julia Neufeld a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Category                                              Chunk\n",
       "2493       Philosophy  Produced by Keith G. RichardsonChrist, Christi...\n",
       "33    Social Sciences  The CRIMINOLOGY SERIES.1. The Female Offender....\n",
       "3683       Philosophy  Produced by Heiko Evermann, Sandra Eder and th...\n",
       "4129  Social Sciences  Produced by Chris Curnow, Paul Clark, and the ...\n",
       "3193       Philosophy  Produced by Juliet Sutherland, Julia Neufeld a..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Utils import build_training_set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "corpus_location = './Documents'  # Path to your document folder\n",
    "num_cases = 3000  # Number of training instances\n",
    "chunk_size = 512  # Experiment with different chunk sizes\n",
    "use_title = False  # Include document title if needed\n",
    "respect_sentence_boundaries = True  # Try both True and False\n",
    "\n",
    "# Build training set\n",
    "df_sampled = build_training_set(num_cases, chunk_size, use_title, respect_sentence_boundaries)\n",
    "df_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573ae5f-9d6f-4753-8f58-62aa00a92e28",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "Split data into train and validation set. Tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "753d737d-761c-4fcd-9765-95933e488cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Category', 'Chunk', 'labels', '__index_level_0__'],\n",
      "    num_rows: 600\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Convert category names to numeric labels\n",
    "category_to_int = {cat: idx for idx, cat in enumerate(df_sampled['Category'].unique())}\n",
    "df_sampled['labels'] = df_sampled['Category'].map(category_to_int)\n",
    "\n",
    "# Split dataset into training and validation\n",
    "train_data, val_data = train_test_split(df_sampled, test_size=0.2)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Chunk'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "# Convert to Hugging Face dataset\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420fd440-c1a9-4184-899d-57cbbe8c4f4e",
   "metadata": {},
   "source": [
    "# Train the model \n",
    "\n",
    "I tried different combinations of Chunk size and sentence alignment. And stored the best model to hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd73f774-b66e-4cf7-bafe-73446adf3de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f802099c468e451096563458a7cff501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20cc1d13b0447e98f8f824f7e5f0678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/exouser/.local/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_914682/855611930.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [900/900 01:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.625800</td>\n",
       "      <td>0.583410</td>\n",
       "      <td>0.763333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.524600</td>\n",
       "      <td>0.628650</td>\n",
       "      <td>0.778333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>0.700690</td>\n",
       "      <td>0.785000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved!\n"
     ]
    }
   ],
   "source": [
    "# Apply tokenization\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(category_to_int))\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./distilbert_text_classification_multiclass_512',\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    hub_model_id='distilbert_text_classification_multiclass_512'\n",
    ")\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    return {'accuracy': accuracy_score(labels, predictions)}\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained('./distilbert_text_classification_multiclass_512')\n",
    "tokenizer.save_pretrained('./distilbert_text_classification_multiclass_512')\n",
    "\n",
    "print(\"Model training complete and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dce2d5-99ff-40ad-870e-cdb40fee134a",
   "metadata": {},
   "source": [
    "# What I tried:\n",
    "1. Chunk size 512, sentence alignment = True (Best accuracy was obtained with these hyperparameters.)\n",
    "2. Chunk size 256, sentence alignment = True\n",
    "3. Chunk size 512, sentence alignment = False\n",
    "4. Chunk size 256, sentence alignment = False\n",
    "\n",
    "To push the best model to hugging face, I renamed path to specific model name. Same for the testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310ae90-ff92-4f6a-8ee2-9e99e78af03f",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20acc3f-847e-4dba-80ec-8d630459a37b",
   "metadata": {},
   "source": [
    "Testing the model before saving it. I got best results for Chunk_size 512 and sentence alignment was set to True. Gave a small chunk from a random document to the model, and it recognized the category correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72c431ba-c9a2-444c-b505-28a224a6c4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: Social Sciences\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "model_path = './distilbert_text_classification_multiclass_512'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Move model to the correct device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Define category mapping (same as during training)\n",
    "category_to_int = {cat: idx for idx, cat in enumerate(df_sampled['Category'].unique())}\n",
    "int_to_category = {v: k for k, v in category_to_int.items()}\n",
    "\n",
    "# Function to predict category\n",
    "def predict_category(text):\n",
    "    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move input to correct device\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations for inference\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()  # Get predicted class index\n",
    "    \n",
    "    return int_to_category[predicted_class]\n",
    "\n",
    "# Test with a sample text\n",
    "# sample_text = \"\"\n",
    "sample_text = \"A Few Words About These United States Population Statistics.All figures listed below for years before 1992 are US CensusBureau figures as per the source files.  Where there were anassortment of figures for a specific year, we averaged them.1992 was an estimate.  Years after 1992 are our estimates ona predicted growth rate of 1%, as the average growth rate of\"\n",
    "predicted_label = predict_category(sample_text)\n",
    "print(f\"Predicted Category: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d101c7-14ff-4ab7-b3cd-ac33114103cc",
   "metadata": {},
   "source": [
    "# Save best model to Hugging face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24f6d3-8b52-4a1a-9154-6cbaca6c12ba",
   "metadata": {},
   "source": [
    "Saving model to hugging face. Here is the link to my model. \n",
    "https://huggingface.co/gaurinm30/distilbert_text_classification_multiclass_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "effd511b-86ba-4383-8f0b-e5114614e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON file\n",
    "with open('secrets.json', 'r') as file:\n",
    "    secrets = json.load(file)\n",
    "\n",
    "HF_TOKEN = secrets[\"HF_TOKEN\"]\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "251bb03a-ab8f-445c-86a5-aec32fd6204c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76476d5c4b8b4fb0a682178cdddb8e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ec0114d58d41548d5318de26ebabce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e1716df2974d1e8689eb8324447741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/gaurinm30/distilbert_text_classification_multiclass_512/commit/2b0078370edb32a8108765a5691330931db8bd10', commit_message='End of training', commit_description='', oid='2b0078370edb32a8108765a5691330931db8bd10', pr_url=None, repo_url=RepoUrl('https://huggingface.co/gaurinm30/distilbert_text_classification_multiclass_512', endpoint='https://huggingface.co', repo_type='model', repo_id='gaurinm30/distilbert_text_classification_multiclass_512'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import upload_file\n",
    "\n",
    "# Upload model to Hugging Face Hub\n",
    "trainer.push_to_hub()\n",
    "# model.push_to_hub(\"distilbert_text_classification_multiclass_512\")\n",
    "# tokenizer.push_to_hub(\"distilbert_text_classification_multiclass_512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb5a19-466a-4e1e-830e-4c1d068fe52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc69498-08be-4acd-9d65-13f06706f99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e8a07-e3ec-49c0-9b41-6ad09ca3460b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881ef65-9e11-4243-919f-8284e73b1fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
